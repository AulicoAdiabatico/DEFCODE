{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "import keras.utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import keras.regularizers as kr\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import keras.losses as ls\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pydot\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###In questa parte si selezionano gli oggetti per il training. In automatico \n",
    "###i dati vengono selezionati, eliminati i dati con più di 4 elementi pari a\n",
    "###zero e vengono selezionate randomicamente delle stelle da usare come \n",
    "###training dataset. La dimensione relativa tra train set e validation set\n",
    "###è controllata dal parametro traindim.\n",
    "\n",
    "data=pd.read_csv('./Data/DEFMSData.csv')\n",
    "nancount=[]\n",
    "ind=[]\n",
    "for i in range(0,data.shape[0]):\n",
    "    nancount.append(data.iloc[i,12:].isnull().sum())\n",
    "    if nancount[i]<5:\n",
    "        ind.append(i)\n",
    "    else:\n",
    "        pass\n",
    "data=data.iloc[ind,:]\n",
    "subselect=['NGC2547','NGC2516','NGC6253','M67','NGC6633']\n",
    "data=data.set_index(['GES_FLD'])\n",
    "data=data.loc[subselect,:]\n",
    "l=[0]\n",
    "l2=[0]\n",
    "for i in range(0,len(subselect)):\n",
    "    b=np.sum(l)+data.loc[subselect[i],:].shape[0]\n",
    "    l2.append(b)\n",
    "    a=data.loc[subselect[i],:].shape[0]\n",
    "    l.append(a)\n",
    "traindim=0.85\n",
    "subseltrain=[]\n",
    "subseltest=[]\n",
    "for j in range(0,len(subselect)):\n",
    "    subseltrain=np.concatenate((subseltrain,np.random.choice(range(l2[j],l2[j+1]),round(l[j+1]*traindim),replace=False)))\n",
    "subseltrain=subseltrain.astype(int)\n",
    "for k in range(0,data.shape[0]):\n",
    "    if k in subseltrain:\n",
    "        pass\n",
    "    else:\n",
    "        subseltest.append(k)\n",
    "subseltest=np.array(subseltest)\n",
    "\n",
    "data=data.reset_index()   \n",
    "dataset=data.values    \n",
    "\n",
    "invartrain=dataset[subseltrain,12:].astype(float)\n",
    "invartrain=np.nan_to_num(invartrain)\n",
    "outvartrain=dataset[subseltrain,0]\n",
    "invarfit=dataset[subseltest,12:].astype(float)\n",
    "invarfit=np.nan_to_num(invarfit)\n",
    "outvarfit=dataset[subseltest,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Viene generato il file con le label degli oggetti.\n",
    "\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(outvartrain)\n",
    "encodedout=encoder.transform(outvartrain)\n",
    "dummyout=np_utils.to_categorical(encodedout)\n",
    "encoder.fit(outvarfit)\n",
    "encout=encoder.transform(outvarfit)\n",
    "dummytest=np_utils.to_categorical(encout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Modello di rete. La dimensione dei layer varia al variare della dimensione\n",
    "###dell'input. \n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(invartrain.shape[1],input_dim=invartrain.shape[1],activation='selu',kernel_regularizer=kr.l1(0.01)))\n",
    "model.add(Dense(round(invartrain.shape[1]*2/5),activation='selu',kernel_regularizer=kr.l1(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3,activation='softsign'))\n",
    "model.add(Dense(dummyout.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Training\n",
    "\n",
    "history=model.fit(invartrain,dummyout,validation_data=(invarfit,dummytest),epochs=10000,batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Valutazione del training fatto, i valori finali vengono printati dalla\n",
    "###cell successiva.\n",
    "\n",
    "trainmse=model.evaluate(invartrain,dummyout,verbose=0)\n",
    "testmse=model.evaluate(invarfit,dummytest,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainmse,testmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Plot delle Loss\n",
    "\n",
    "plt.close()\n",
    "plt.title('Train vs Test Loss Functions')\n",
    "plt.xlabel('Ages')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(history.history['loss'], label='Train set')\n",
    "plt.plot(history.history['val_loss'], label='Test set')\n",
    "#plt.plot(history.history['val_accuracy'],label='accuracy',linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Vengono salvati i weights e bias in 6 file distinti, che verranno caricati nel prossimo file:\n",
    "###MSFinalNN. NB sono disponibili i weights trovati da me nella cartella FixedWeights.\n",
    "\n",
    "fixedw=model.get_weights()\n",
    "l0=model.layers[0].get_weights()\n",
    "np.save('./EvalWeights/msl0.npy',l0[0])\n",
    "np.save('./EvalWeights/msl0bias.npy',l0[1])\n",
    "l1=model.layers[1].get_weights()\n",
    "np.save('./EvalWeights/msl1.npy',l1[0])\n",
    "np.save('./EvalWeights/msl1bias.npy',l1[1])\n",
    "l2=model.layers[3].get_weights()\n",
    "np.save('./EvalWeights/msl2.npy',l2[0])\n",
    "np.save('./EvalWeights/msl2bias.npy',l2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
